{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRN model impleted by Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from IPython import embed\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import shutil\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "code_folding": [
     2,
     20,
     41,
     75,
     83,
     102,
     123
    ]
   },
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "\n",
    "def read_KB(KB_file):\n",
    "    # example in KB_file: KBs.txt h \\t r \\t t\n",
    "    entities = set()\n",
    "    relations = set()\n",
    "    if os.path.isfile(KB_file):\n",
    "        with open(KB_file) as f:\n",
    "            lines = f.readlines()\n",
    "    else:\n",
    "        raise Exception(\"!! %s is not found!!\" % KB_file)\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip().split('\\t')\n",
    "        entities.add(line[0])\n",
    "        entities.add(line[2])\n",
    "        relations.add(line[1])\n",
    "    return entities, relations\n",
    "\n",
    "\n",
    "def get_KB(KB_file, ent2id, rel2id):\n",
    "    nwords = len(ent2id)\n",
    "    nrels = len(rel2id)\n",
    "    tails = np.zeros([nwords*nrels, 1], 'int32')\n",
    "    KBmatrix = np.zeros([nwords * nrels, nwords], 'int32')\n",
    "    Triples = []\n",
    "\n",
    "    f = open(KB_file)\n",
    "    for line in f.readlines():\n",
    "        line = line.strip().split('\\t')\n",
    "        h = ent2id[line[0]]\n",
    "        r = rel2id[line[1]]\n",
    "        t = ent2id[line[2]]\n",
    "        Triples.append([h, r, t])\n",
    "        lenlist = tails[h*nrels+r]\n",
    "        KBmatrix[h*nrels+r, lenlist] = t\n",
    "        tails[h*nrels+r] += 1\n",
    "    \n",
    "    return np.array(Triples), KBmatrix[:, :np.max(tails)], np.max(tails)\n",
    "\n",
    "\n",
    "def read_data(data_file):\n",
    "    if os.path.isfile(data_file):\n",
    "        with open(data_file) as f:\n",
    "            lines = f.readlines()\n",
    "    else:\n",
    "        raise Exception(\"!! %s is not found!!\" % data_file)\n",
    "\n",
    "    words = set()\n",
    "    data = []\n",
    "    questions = []\n",
    "    doc = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip().split('\\t')\n",
    "        qlist = line[0].strip().split()\n",
    "        k = line[1].find('(')\n",
    "        if not k == -1:\n",
    "            if line[1][k-1] == '_':\n",
    "                k += (line[1][k+1:-1].find('(') + 1)\n",
    "            asset = line[1][k+1:-1]\n",
    "            line[1] = line[1][:k]\n",
    "        else:\n",
    "            asset = line[3]\n",
    "        data.append([line[0], line[1], line[2], asset])\n",
    "\n",
    "        for w in qlist:\n",
    "            words.add(w)\n",
    "        questions.append(qlist)\n",
    "\n",
    "    sentence_size = max(len(i) for i in questions)\n",
    "\n",
    "    return words, data, sentence_size\n",
    "\n",
    "\n",
    "def tokenize(sent):\n",
    "    '''Return the tokens of a sentence including punctuation.\n",
    "    >>> tokenize('Bob dropped the apple. Where is the apple?')\n",
    "    ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n",
    "    '''\n",
    "    return [x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]\n",
    "\n",
    "\n",
    "def MultiAcc(labels,preds,length):\n",
    "    #length = path = 2 * hop + 1   (hop == path_l + cons_l + final == path_l * 2 + 1 )\n",
    "    #compare path and final answer accuracy\n",
    "    Acc = []\n",
    "\n",
    "    for i in range(length):\n",
    "        Acc.append(round(metrics.accuracy_score(labels[:,i],preds[:,i]),3))\n",
    "\n",
    "    batch_size = preds.shape[0]\n",
    "    correct = 0.0\n",
    "    for j in range(batch_size):\n",
    "        k = length - 1\n",
    "        while(labels[j,k]==0):\n",
    "            k -= 2\n",
    "        if(labels[j,k]==preds[j,k]):\n",
    "            correct += 1.0   #final answer accuracy \n",
    "    Acc.append(round( correct/batch_size ,3))\n",
    "    return Acc\n",
    "\n",
    "def InSet(labels,anset,preds):\n",
    "    #get accuracy(whether in answer set or not)\n",
    "    #labels does not matter\n",
    "    #preds is path-list\n",
    "    #labels is path-labels\n",
    "    right = 0.0\n",
    "    for i in range(len(anset)):\n",
    "        if type(preds[i]) is np.int64:\n",
    "            ans_pred = preds[i]\n",
    "        else:\n",
    "            ans_pred = preds[i,-1]\n",
    "            '''\n",
    "            k = len(labels[0]) - 1\n",
    "            while(labels[i,k]==0):\n",
    "                k -= 2\n",
    "            ans_pred = preds[i,k]\n",
    "            '''\n",
    "        if ans_pred in anset[i]:\n",
    "            right += 1\n",
    "    return round(right/len(anset), 3)\n",
    "\n",
    "def process_data(KB_file, data_file):\n",
    "    entities, relations = read_KB(KB_file)\n",
    "    words, data, sentence_size = read_data(data_file)\n",
    "\n",
    "    word2id = {}\n",
    "    ent2id = {}\n",
    "    rel2id = {}\n",
    "\n",
    "    word2id['<unk>'] = 0\n",
    "    rel2id['<end>'] = 0\n",
    "    ent2id['<unk>'] = 0\n",
    "\n",
    "    for r in relations:\n",
    "        # same r_id in rel2id and word2id\n",
    "        if r not in rel2id.keys():\n",
    "            rel2id[r] = len(rel2id)\n",
    "        if r not in word2id.keys():\n",
    "            word2id[r] = len(word2id)\n",
    "    for e in entities:\n",
    "        if e not in ent2id.keys():\n",
    "            ent2id[e] = len(ent2id)\n",
    "    for word in words:\n",
    "        if word not in word2id.keys():\n",
    "            word2id[word] = len(word2id)\n",
    "\n",
    "    print('here are %d words in word2id(vocab)' % len(word2id))\n",
    "    print('here are %d relations in rel2id(rel_vocab)' % len(rel2id))\n",
    "    print('here are %d entities in ent2id(ent_vocab)' % len(ent2id))\n",
    "\n",
    "    Triples, KBs, tails_size = get_KB(KB_file, ent2id, rel2id)\n",
    "\n",
    "    print(\"The number of records or triples\", len(np.nonzero(KBs)[0]))\n",
    "\n",
    "    Q = []\n",
    "    QQ = []\n",
    "    A = []\n",
    "    AA = []\n",
    "    P = []\n",
    "    PP = []\n",
    "    S = []\n",
    "    SS = []\n",
    "\n",
    "    for query, answer, path, answerset in data:\n",
    "        path = path.strip().split('#')[0:5]  # path = [s,r1,m,r2,t]\n",
    "\n",
    "        query = query.strip().split()\n",
    "        ls = max(0, sentence_size-len(query))\n",
    "        q = [word2id[w] for w in query] + [0] * ls\n",
    "        Q.append(q)\n",
    "        QQ.append(query)\n",
    "\n",
    "\n",
    "        a = np.zeros(len(ent2id))  # if use new ans-vocab, add 0 for 'end'\n",
    "        a[ent2id[answer]] = 1\n",
    "        A.append(a)\n",
    "        AA.append(ent2id[answer])\n",
    "\n",
    "        p = []\n",
    "        for i in range(len(path)):\n",
    "            if i % 2 == 0:\n",
    "                e = ent2id[path[i]]\n",
    "                p.append(e)\n",
    "            else:\n",
    "                r = rel2id[path[i]]\n",
    "                p.append(r)\n",
    "\n",
    "        P.append(p)\n",
    "        PP.append(path)\n",
    "\n",
    "        anset = answerset.split('/')\n",
    "        anset = anset[:-1]\n",
    "        ass = []\n",
    "        for a in anset:\n",
    "            ass.append(ent2id[a])\n",
    "        S.append(ass)\n",
    "        SS.append(anset)\n",
    "\n",
    "    return np.array(Q), np.array(A), np.array(P), np.array(S), Triples, sentence_size, word2id, ent2id, rel2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {
    "code_folding": [
     19,
     111,
     188
    ]
   },
   "outputs": [],
   "source": [
    "class IRN(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(IRN, self).__init__()\n",
    "        self._margin = 4  # 外边距\n",
    "        self._batch_size = args[\"batch_size\"]\n",
    "        self._vocab_size = args[\"nwords\"]\n",
    "        self._rel_size = args[\"nrels\"]\n",
    "        self._ent_size = args[\"nents\"]\n",
    "        self._sentence_size = args[\"query_size\"]\n",
    "        self._embedding_size = args[\"edim\"]\n",
    "        self._path_size = args[\"path_size\"]\n",
    "        self._hops = int(args[\"nhop\"])\n",
    "        self._max_grad_norm = args[\"max_grad_norm\"]\n",
    "        self._name = \"IRN\"\n",
    "        self._inner_epochs = args[\"inner_nepoch\"]\n",
    "        self._checkpoint_dir = args[\"checkpoint_dir\"] + '/' + self._name\n",
    "        self.build_vars()\n",
    "\n",
    "\n",
    "    def forward(self, KBs, queries, answers, answers_id, paths):\n",
    "        nexample = queries.shape[0]\n",
    "        keys = np.repeat(np.reshape(np.arange(self._rel_size), [1, -1]),\n",
    "                         nexample,\n",
    "                         axis=0)\n",
    "        pad = np.arange(nexample)\n",
    "        ones = np.ones(nexample)\n",
    "        zeros = np.zeros(nexample)\n",
    "        \n",
    "        loss = torch.Tensor(zeros).unsqueeze(1)\n",
    "        s_index = torch.Tensor(paths[:, 0]).unsqueeze(1)\n",
    "        q_emb = self.Q[torch.LongTensor(queries)]\n",
    "        q = torch.sum(q_emb, dim=1)\n",
    "        state = self.E[s_index.long()].squeeze(1)\n",
    "        p = s_index\n",
    "        for hop in range(self._hops):\n",
    "            step = 2 * hop\n",
    "            gate = torch.matmul(q, torch.matmul(self.R, self.Mrq).t())+torch.matmul(state, torch.matmul(self.R, self.Mrs).t())\n",
    "            rel_logits = gate\n",
    "            r_index = torch.argmax(rel_logits, dim=1)\n",
    "            gate = torch.softmax(gate,dim=1)\n",
    "            real_rel_onehot = torch.Tensor(paths[:, step + 1])\n",
    "            \n",
    "            predict_rel_onehot = torch.nn.functional.one_hot(r_index, num_classes=self._rel_size)\n",
    "            state = state + torch.matmul(gate, torch.matmul(self.R, self.Mrs))\n",
    "            critrion = nn.CrossEntropyLoss(reduce=False)\n",
    "            loss += critrion(rel_logits, real_rel_onehot.long()).unsqueeze(1)\n",
    "            \n",
    "            q = q - torch.matmul(gate, torch.matmul(self.R, self.Mrq))\n",
    "            value = torch.matmul(state, self.Mse)\n",
    "            ans = torch.matmul(value, self.E.t())\n",
    "            t_index = torch.argmax(ans, dim=1).float()\n",
    "            r_index = r_index.float()\n",
    "            t_index = r_index/(r_index+1e-15)*t_index + \\\n",
    "                (1-r_index/(r_index+1e-15)) * p[:, -1].float()\n",
    "\n",
    "            p = torch.cat((p, r_index.float().view(-1, 1)), dim=1)\n",
    "            p = torch.cat((p, t_index.float().view(-1, 1)), dim=1)\n",
    "\n",
    "            real_ans_onehot = torch.Tensor(paths[:, step + 2])\n",
    "            loss += critrion(ans, real_ans_onehot.long()).unsqueeze(1)\n",
    "        \n",
    "        loss = torch.sum(loss)\n",
    "        self.E.data = self.E.data / (torch.pow(self.E.data, 2).sum(dim=1, keepdim=True))\n",
    "        self.R.data = self.R.data / (torch.pow(self.R.data, 2).sum(dim=1, keepdim=True))\n",
    "        self.Q.data = self.Q.data / (torch.pow(self.Q.data, 2).sum(dim=1, keepdim=True))\n",
    "        return loss\n",
    "\n",
    "    def build_vars(self):\n",
    "        nil_word_slot = torch.zeros(1, self._embedding_size)\n",
    "        nil_rel_slot = torch.zeros(1, self._embedding_size)\n",
    "        '''\n",
    "        self.E = nn.Parameter(\n",
    "            torch.cat(\n",
    "                (nil_word_slot,\n",
    "                 nn.init.xavier_normal_(\n",
    "                     torch.Tensor(self._ent_size - 1, self._embedding_size))),\n",
    "                dim=0))\n",
    "        self.Q = nn.Parameter(\n",
    "            torch.cat((nil_word_slot,\n",
    "                       nn.init.xavier_normal_(\n",
    "                           torch.Tensor(self._vocab_size - 1,\n",
    "                                        self._embedding_size))),\n",
    "                      dim=0))\n",
    "        self.R = nn.Parameter(\n",
    "            torch.cat(\n",
    "                (nil_rel_slot,\n",
    "                 nn.init.xavier_normal_(\n",
    "                     torch.Tensor(self._rel_size - 1, self._embedding_size))),\n",
    "                dim=0))\n",
    "        '''\n",
    "        self.E = nn.Parameter(nn.init.xavier_normal_(torch.Tensor(self._ent_size, self._embedding_size)))\n",
    "        self.Q = nn.Parameter(nn.init.xavier_normal_(torch.Tensor(self._vocab_size, self._embedding_size)))\n",
    "        self.R = nn.Parameter(nn.init.xavier_normal_(torch.Tensor(self._rel_size, self._embedding_size)))\n",
    "\n",
    "        self.Mrq = nn.Parameter(\n",
    "            nn.init.xavier_normal_(\n",
    "                torch.Tensor(self._embedding_size, self._embedding_size)))\n",
    "        self.Mrs = nn.Parameter(\n",
    "            nn.init.xavier_normal_(\n",
    "                torch.Tensor(self._embedding_size, self._embedding_size)))\n",
    "        self.Mse = nn.Parameter(\n",
    "            nn.init.xavier_normal_(\n",
    "                torch.Tensor(self._embedding_size, self._embedding_size)))\n",
    "\n",
    "        self._zeros = torch.zeros(1)\n",
    "\n",
    "    def match(self):\n",
    "        Similar = torch.matmul(torch.matmul(self.R, self.Mrq), self.Q.t())\n",
    "        _, idx = torch.topk(Similar, 5)\n",
    "        return idx\n",
    "\n",
    "    def batch_pretrain(self, KBs, queries, answers, answers_id, paths):\n",
    "        nexample = KBs.shape[0]\n",
    "        keys = np.repeat(np.reshape(np.arange(self._rel_size), [1, -1]),\n",
    "                         nexample,\n",
    "                         axis=0)\n",
    "        pad = np.random.randint(low=0, high=self._ent_size, size=nexample)\n",
    "        ones = np.ones(nexample)\n",
    "        zeros = np.zeros(nexample)\n",
    "    \n",
    "        h = torch.Tensor(KBs[:, 0])\n",
    "        r = torch.Tensor(KBs[:, 1])\n",
    "        t = torch.Tensor(KBs[:, 2])\n",
    "        tt = torch.Tensor(pad)\n",
    "        h_emb = self.E[h.long()]\n",
    "        r_emb = self.R[r.long()]\n",
    "        t_emb = self.E[t.long()]\n",
    "        tt_emb = self.E[tt.long()]\n",
    "        l_emb = torch.matmul((h_emb + r_emb), self.Mse)\n",
    "        s = (l_emb - t_emb) * (l_emb - t_emb)\n",
    "        ss = (l_emb - tt_emb) * (l_emb - tt_emb)\n",
    "        \n",
    "        loss = self._margin + torch.sum(s, dim=1) - torch.sum(ss, dim=1)\n",
    "        loss = torch.clamp(loss, min=0)\n",
    "        \n",
    "        loss = torch.sum(loss)\n",
    "        return loss\n",
    "\n",
    "    def batch_fit(self, KBs, queries, answers, answers_id, paths):\n",
    "        nexample = queries.shape[0]\n",
    "        keys = np.repeat(np.reshape(np.arange(self._rel_size), [1, -1]),\n",
    "                         nexample,\n",
    "                         axis=0)\n",
    "        pad = np.arange(nexample)\n",
    "        ones = np.ones(nexample)\n",
    "        zeros = np.zeros(nexample)\n",
    "        print(self.Q)\n",
    "        loss = torch.Tensor(zeros).unsqueeze(1)\n",
    "        s_index = torch.Tensor(paths[:, 0]).unsqueeze(1)\n",
    "        q_emb = self.Q[torch.LongTensor(queries)]\n",
    "        q = torch.sum(q_emb, dim=1)\n",
    "        state = self.E[s_index.long()].squeeze(1)\n",
    "        p = s_index\n",
    "        for hop in range(self._hops):\n",
    "            step = 2 * hop\n",
    "            gate = torch.matmul(q, torch.matmul(self.R, self.Mrq).t())+torch.matmul(state, torch.matmul(self.R, self.Mrs).t())\n",
    "            rel_logits = gate\n",
    "            r_index = torch.argmax(rel_logits, dim=1)\n",
    "            gate = torch.softmax(gate,dim=1)\n",
    "            real_rel_onehot = torch.Tensor(paths[:, step + 1])\n",
    "            \n",
    "            predict_rel_onehot = torch.nn.functional.one_hot(r_index, num_classes=self._rel_size)\n",
    "            state = state + torch.matmul(gate, torch.matmul(self.R, self.Mrs))\n",
    "            critrion = nn.CrossEntropyLoss(reduce=False)\n",
    "            loss += critrion(rel_logits, real_rel_onehot.long()).unsqueeze(1)\n",
    "            \n",
    "            q = q - torch.matmul(gate, torch.matmul(self.R, self.Mrq))\n",
    "            value = torch.matmul(state, self.Mse)\n",
    "            ans = torch.matmul(value, self.E.t())\n",
    "            t_index = torch.argmax(ans, dim=1).float()\n",
    "            r_index = r_index.float()\n",
    "            t_index = r_index/(r_index+1e-15)*t_index + \\\n",
    "                (1-r_index/(r_index+1e-15)) * p[:, -1].float()\n",
    "\n",
    "            p = torch.cat((p, r_index.float().view(-1, 1)), dim=1)\n",
    "            p = torch.cat((p, t_index.float().view(-1, 1)), dim=1)\n",
    "\n",
    "            real_ans_onehot = torch.Tensor(paths[:, step + 2])\n",
    "            loss += critrion(ans, real_ans_onehot.long()).unsqueeze(1)\n",
    "        \n",
    "        loss = torch.sum(loss)\n",
    "        \n",
    "        self.E.data = self.E.data / (torch.pow(self.E.data, 2).sum(dim=1, keepdim=True))\n",
    "        self.R.data = self.R.data / (torch.pow(self.R.data, 2).sum(dim=1, keepdim=True))\n",
    "        self.Q.data = self.Q.data / (torch.pow(self.Q.data, 2).sum(dim=1, keepdim=True))\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def predict(self, KBs, queries, paths):\n",
    "        nexample = queries.shape[0]\n",
    "        keys = np.repeat(np.reshape(np.arange(self._rel_size), [1, -1]),\n",
    "                         nexample,\n",
    "                         axis=0)\n",
    "        pad = np.arange(nexample)\n",
    "        ones = np.ones(nexample)\n",
    "        zeros = np.zeros(nexample)\n",
    "\n",
    "        loss = torch.Tensor(zeros).unsqueeze(1)\n",
    "        s_index = torch.Tensor(paths[:, 0]).unsqueeze(1)\n",
    "        q_emb = self.Q[torch.LongTensor(queries)]\n",
    "        q = torch.sum(q_emb, dim=1)\n",
    "        state = self.E[s_index.long()].squeeze(1)\n",
    "        p = s_index\n",
    "        for hop in range(self._hops):\n",
    "            step = 2 * hop\n",
    "            gate = torch.matmul(q, torch.matmul(self.R, self.Mrq).t())+torch.matmul(state, torch.matmul(self.R, self.Mrs).t())\n",
    "            \n",
    "            rel_logits = gate\n",
    "            \n",
    "            r_index = torch.argmax(rel_logits, dim=1)\n",
    "            gate = torch.softmax(gate,dim=1)\n",
    "            real_rel_onehot = torch.Tensor(paths[:, step + 1])\n",
    "            \n",
    "            predict_rel_onehot = torch.nn.functional.one_hot(r_index, num_classes=self._rel_size)\n",
    "            state = state + torch.matmul(gate, torch.matmul(self.R, self.Mrs))\n",
    "            critrion = nn.CrossEntropyLoss(reduce=False)\n",
    "            \n",
    "            loss += critrion(rel_logits, real_rel_onehot.long()).unsqueeze(1)\n",
    "            \n",
    "            q = q - torch.matmul(gate, torch.matmul(self.R, self.Mrq))\n",
    "            value = torch.matmul(state, self.Mse)\n",
    "            ans = torch.matmul(value, self.E.t())\n",
    "            t_index = torch.argmax(ans, dim=1).float()\n",
    "            r_index = r_index.float()\n",
    "            t_index = r_index/(r_index+1e-15)*t_index + \\\n",
    "                (1-r_index/(r_index+1e-15)) * p[:, -1].float()\n",
    "\n",
    "            p = torch.cat((p, r_index.float().view(-1, 1)), dim=1)\n",
    "            p = torch.cat((p, t_index.float().view(-1, 1)), dim=1)\n",
    "\n",
    "            real_ans_onehot = torch.Tensor(paths[:, step + 2])\n",
    "            loss += critrion(ans, real_ans_onehot.long()).unsqueeze(1)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args[\"edim\"] = 50\n",
    "args[\"nhop\"] = 3\n",
    "args[\"batch_size\"] = 50\n",
    "args[\"nepoch\"] = 5000\n",
    "args[\"inner_nepoch\"] = 3\n",
    "args[\"init_lr\"] = 0.001\n",
    "args[\"epsilon\"] = 1e-8\n",
    "args[\"max_grad_norm\"] = 20\n",
    "args[\"checkpoint_dir\"] = \"checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here are 542 words in word2id(vocab)\n",
      "here are 14 relations in rel2id(rel_vocab)\n",
      "here are 1057 entities in ent2id(ent_vocab)\n",
      "The number of records or triples 1211\n",
      "read data cost 0.095364 seconds\n",
      "(1528, 13) (1528, 1057) (1528, 5) (1528,)\n"
     ]
    }
   ],
   "source": [
    "KB_file = 'data/2H-kb.txt'\n",
    "data_file = 'data/2H.txt'\n",
    "start = time.time()\n",
    "Q,A,P,S,Triples,args[\"query_size\"], word2id, ent2id, rel2id = process_data(KB_file, data_file)\n",
    "args[\"path_size\"] = len(P[0])\n",
    "args[\"nhop\"] = args[\"path_size\"] / 2\n",
    "\n",
    "\n",
    "print (\"read data cost %f seconds\" %(time.time()-start))\n",
    "args[\"nwords\"] = len(word2id) \n",
    "args[\"nrels\"] = len(rel2id) \n",
    "args[\"nents\"] = len(ent2id)\n",
    "\n",
    "trainQ, testQ, trainA, testA, trainP, testP, trainS, testS = train_test_split(Q, A, P, S, test_size=.1, random_state=123)\n",
    "trainQ, validQ, trainA, validA, trainP, validP, trainS, validS = train_test_split(trainQ, trainA, trainP, trainS, test_size=.11, random_state=0)\n",
    "\n",
    "n_train = trainQ.shape[0]     \n",
    "n_test = testQ.shape[0]\n",
    "n_val = validQ.shape[0]\n",
    "print(trainQ.shape, trainA.shape,trainP.shape,trainS.shape)\n",
    "\n",
    "# 找到答案所在的坐标\n",
    "train_labels = np.argmax(trainA, axis=1)\n",
    "test_labels = np.argmax(testA, axis=1)\n",
    "valid_labels = np.argmax(validA, axis=1)\n",
    "batches = list(zip(range(0, n_train-args[\"batch_size\"], args[\"batch_size\"]), range(args[\"batch_size\"], n_train, args[\"batch_size\"])))\n",
    "pre_batches = list(zip(range(0, Triples.shape[0]-args[\"batch_size\"], args[\"batch_size\"]), range(args[\"batch_size\"], Triples.shape[0], args[\"batch_size\"])))\n",
    "\n",
    "\n",
    "model = IRN(args)\n",
    "optimizer = optim.Adam(model.parameters(), args[\"init_lr\"],weight_decay=1e-5)\n",
    "pre_val_preds = model.predict(Triples, validQ, validP)\n",
    "pre_test_preds = model.predict(Triples, testQ, testP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Epoch 0\n",
      "Train Accuracy: 0.099\n",
      "Validation Accuracy: 0.063\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 1\n",
      "Train Accuracy: 0.098\n",
      "Validation Accuracy: 0.058\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 2\n",
      "Train Accuracy: 0.205\n",
      "Validation Accuracy: 0.148\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 3\n",
      "Train Accuracy: 0.241\n",
      "Validation Accuracy: 0.18\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 4\n",
      "Train Accuracy: 0.266\n",
      "Validation Accuracy: 0.243\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 5\n",
      "Train Accuracy: 0.259\n",
      "Validation Accuracy: 0.212\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 6\n",
      "Train Accuracy: 0.269\n",
      "Validation Accuracy: 0.222\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 7\n",
      "Train Accuracy: 0.307\n",
      "Validation Accuracy: 0.265\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 8\n",
      "Train Accuracy: 0.329\n",
      "Validation Accuracy: 0.275\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 9\n",
      "Train Accuracy: 0.338\n",
      "Validation Accuracy: 0.28\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 10\n",
      "Train Accuracy: 0.366\n",
      "Validation Accuracy: 0.296\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 11\n",
      "Train Accuracy: 0.397\n",
      "Validation Accuracy: 0.302\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 12\n",
      "Train Accuracy: 0.427\n",
      "Validation Accuracy: 0.323\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 13\n",
      "Train Accuracy: 0.443\n",
      "Validation Accuracy: 0.344\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 14\n",
      "Train Accuracy: 0.474\n",
      "Validation Accuracy: 0.323\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 15\n",
      "Train Accuracy: 0.53\n",
      "Validation Accuracy: 0.402\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 16\n",
      "Train Accuracy: 0.509\n",
      "Validation Accuracy: 0.386\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 17\n",
      "Train Accuracy: 0.565\n",
      "Validation Accuracy: 0.386\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 18\n",
      "Train Accuracy: 0.623\n",
      "Validation Accuracy: 0.429\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 19\n",
      "Train Accuracy: 0.599\n",
      "Validation Accuracy: 0.418\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 20\n",
      "Train Accuracy: 0.606\n",
      "Validation Accuracy: 0.471\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 21\n",
      "Train Accuracy: 0.634\n",
      "Validation Accuracy: 0.444\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 22\n",
      "Train Accuracy: 0.681\n",
      "Validation Accuracy: 0.444\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 23\n",
      "Train Accuracy: 0.668\n",
      "Validation Accuracy: 0.46\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 24\n",
      "Train Accuracy: 0.719\n",
      "Validation Accuracy: 0.54\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 25\n",
      "Train Accuracy: 0.755\n",
      "Validation Accuracy: 0.54\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 26\n",
      "Train Accuracy: 0.764\n",
      "Validation Accuracy: 0.534\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 27\n",
      "Train Accuracy: 0.78\n",
      "Validation Accuracy: 0.587\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 28\n",
      "Train Accuracy: 0.764\n",
      "Validation Accuracy: 0.577\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 29\n",
      "Train Accuracy: 0.782\n",
      "Validation Accuracy: 0.577\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 30\n",
      "Train Accuracy: 0.813\n",
      "Validation Accuracy: 0.603\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 31\n",
      "Train Accuracy: 0.793\n",
      "Validation Accuracy: 0.624\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 32\n",
      "Train Accuracy: 0.797\n",
      "Validation Accuracy: 0.64\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 33\n",
      "Train Accuracy: 0.82\n",
      "Validation Accuracy: 0.63\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 34\n",
      "Train Accuracy: 0.839\n",
      "Validation Accuracy: 0.698\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 35\n",
      "Train Accuracy: 0.843\n",
      "Validation Accuracy: 0.683\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 36\n",
      "Train Accuracy: 0.859\n",
      "Validation Accuracy: 0.683\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 37\n",
      "Train Accuracy: 0.872\n",
      "Validation Accuracy: 0.72\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 38\n",
      "Train Accuracy: 0.874\n",
      "Validation Accuracy: 0.72\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 39\n",
      "Train Accuracy: 0.852\n",
      "Validation Accuracy: 0.709\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 40\n",
      "Train Accuracy: 0.882\n",
      "Validation Accuracy: 0.709\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 41\n",
      "Train Accuracy: 0.869\n",
      "Validation Accuracy: 0.677\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 42\n",
      "Train Accuracy: 0.866\n",
      "Validation Accuracy: 0.704\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 43\n",
      "Train Accuracy: 0.874\n",
      "Validation Accuracy: 0.709\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 44\n",
      "Train Accuracy: 0.904\n",
      "Validation Accuracy: 0.751\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 45\n",
      "Train Accuracy: 0.901\n",
      "Validation Accuracy: 0.746\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 46\n",
      "Train Accuracy: 0.927\n",
      "Validation Accuracy: 0.762\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 47\n",
      "Train Accuracy: 0.914\n",
      "Validation Accuracy: 0.751\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 48\n",
      "Train Accuracy: 0.912\n",
      "Validation Accuracy: 0.762\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 49\n",
      "Train Accuracy: 0.904\n",
      "Validation Accuracy: 0.788\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 50\n",
      "Train Accuracy: 0.91\n",
      "Validation Accuracy: 0.804\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 51\n",
      "Train Accuracy: 0.891\n",
      "Validation Accuracy: 0.767\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 52\n",
      "Train Accuracy: 0.908\n",
      "Validation Accuracy: 0.783\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 53\n",
      "Train Accuracy: 0.94\n",
      "Validation Accuracy: 0.804\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 54\n",
      "Train Accuracy: 0.916\n",
      "Validation Accuracy: 0.778\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 55\n",
      "Train Accuracy: 0.923\n",
      "Validation Accuracy: 0.799\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 56\n",
      "Train Accuracy: 0.928\n",
      "Validation Accuracy: 0.799\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 57\n",
      "Train Accuracy: 0.938\n",
      "Validation Accuracy: 0.799\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 58\n",
      "Train Accuracy: 0.944\n",
      "Validation Accuracy: 0.831\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 59\n",
      "Train Accuracy: 0.94\n",
      "Validation Accuracy: 0.82\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 60\n",
      "Train Accuracy: 0.922\n",
      "Validation Accuracy: 0.82\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 61\n",
      "Train Accuracy: 0.952\n",
      "Validation Accuracy: 0.815\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 62\n",
      "Train Accuracy: 0.94\n",
      "Validation Accuracy: 0.815\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 63\n",
      "Train Accuracy: 0.917\n",
      "Validation Accuracy: 0.82\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 64\n",
      "Train Accuracy: 0.95\n",
      "Validation Accuracy: 0.852\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 65\n",
      "Train Accuracy: 0.961\n",
      "Validation Accuracy: 0.852\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 66\n",
      "Train Accuracy: 0.953\n",
      "Validation Accuracy: 0.841\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 67\n",
      "Train Accuracy: 0.941\n",
      "Validation Accuracy: 0.836\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 68\n",
      "Train Accuracy: 0.93\n",
      "Validation Accuracy: 0.82\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 69\n",
      "Train Accuracy: 0.929\n",
      "Validation Accuracy: 0.81\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 70\n",
      "Train Accuracy: 0.95\n",
      "Validation Accuracy: 0.799\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 71\n",
      "Train Accuracy: 0.954\n",
      "Validation Accuracy: 0.831\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 72\n",
      "Train Accuracy: 0.949\n",
      "Validation Accuracy: 0.847\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 73\n",
      "Train Accuracy: 0.944\n",
      "Validation Accuracy: 0.81\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 74\n",
      "Train Accuracy: 0.957\n",
      "Validation Accuracy: 0.841\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 75\n",
      "Train Accuracy: 0.949\n",
      "Validation Accuracy: 0.836\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 76\n",
      "Train Accuracy: 0.952\n",
      "Validation Accuracy: 0.831\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 77\n",
      "Train Accuracy: 0.965\n",
      "Validation Accuracy: 0.868\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Epoch 78\n",
      "Train Accuracy: 0.931\n",
      "Validation Accuracy: 0.788\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 79\n",
      "Train Accuracy: 0.954\n",
      "Validation Accuracy: 0.82\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 80\n",
      "Train Accuracy: 0.963\n",
      "Validation Accuracy: 0.836\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 81\n",
      "Train Accuracy: 0.952\n",
      "Validation Accuracy: 0.847\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 82\n",
      "Train Accuracy: 0.948\n",
      "Validation Accuracy: 0.82\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 83\n",
      "Train Accuracy: 0.949\n",
      "Validation Accuracy: 0.857\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 84\n",
      "Train Accuracy: 0.953\n",
      "Validation Accuracy: 0.857\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 85\n",
      "Train Accuracy: 0.967\n",
      "Validation Accuracy: 0.862\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 86\n",
      "Train Accuracy: 0.965\n",
      "Validation Accuracy: 0.852\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 87\n",
      "Train Accuracy: 0.953\n",
      "Validation Accuracy: 0.852\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 88\n",
      "Train Accuracy: 0.967\n",
      "Validation Accuracy: 0.847\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 89\n",
      "Train Accuracy: 0.952\n",
      "Validation Accuracy: 0.857\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 90\n",
      "Train Accuracy: 0.964\n",
      "Validation Accuracy: 0.852\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 91\n",
      "Train Accuracy: 0.95\n",
      "Validation Accuracy: 0.847\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 92\n",
      "Train Accuracy: 0.952\n",
      "Validation Accuracy: 0.825\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 93\n",
      "Train Accuracy: 0.932\n",
      "Validation Accuracy: 0.852\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 94\n",
      "Train Accuracy: 0.955\n",
      "Validation Accuracy: 0.847\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 95\n",
      "Train Accuracy: 0.955\n",
      "Validation Accuracy: 0.794\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 96\n",
      "Train Accuracy: 0.945\n",
      "Validation Accuracy: 0.847\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 97\n",
      "Train Accuracy: 0.949\n",
      "Validation Accuracy: 0.836\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 98\n",
      "Train Accuracy: 0.953\n",
      "Validation Accuracy: 0.804\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 99\n",
      "Train Accuracy: 0.954\n",
      "Validation Accuracy: 0.878\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 100\n",
      "Train Accuracy: 0.965\n",
      "Validation Accuracy: 0.857\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 101\n",
      "Train Accuracy: 0.976\n",
      "Validation Accuracy: 0.884\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 102\n",
      "Train Accuracy: 0.968\n",
      "Validation Accuracy: 0.878\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 103\n",
      "Train Accuracy: 0.947\n",
      "Validation Accuracy: 0.868\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 104\n",
      "Train Accuracy: 0.953\n",
      "Validation Accuracy: 0.862\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 105\n",
      "Train Accuracy: 0.944\n",
      "Validation Accuracy: 0.857\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 106\n",
      "Train Accuracy: 0.976\n",
      "Validation Accuracy: 0.847\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 107\n",
      "Train Accuracy: 0.953\n",
      "Validation Accuracy: 0.862\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 108\n",
      "Train Accuracy: 0.967\n",
      "Validation Accuracy: 0.852\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 109\n",
      "Train Accuracy: 0.962\n",
      "Validation Accuracy: 0.862\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 110\n",
      "Train Accuracy: 0.95\n",
      "Validation Accuracy: 0.831\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 111\n",
      "Train Accuracy: 0.967\n",
      "Validation Accuracy: 0.878\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 112\n",
      "Train Accuracy: 0.958\n",
      "Validation Accuracy: 0.836\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 113\n",
      "Train Accuracy: 0.967\n",
      "Validation Accuracy: 0.847\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 114\n",
      "Train Accuracy: 0.959\n",
      "Validation Accuracy: 0.831\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 115\n",
      "Train Accuracy: 0.927\n",
      "Validation Accuracy: 0.831\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 116\n",
      "Train Accuracy: 0.959\n",
      "Validation Accuracy: 0.857\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 117\n",
      "Train Accuracy: 0.95\n",
      "Validation Accuracy: 0.852\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 118\n",
      "Train Accuracy: 0.966\n",
      "Validation Accuracy: 0.852\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 119\n",
      "Train Accuracy: 0.965\n",
      "Validation Accuracy: 0.852\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 120\n",
      "Train Accuracy: 0.965\n",
      "Validation Accuracy: 0.852\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 121\n",
      "Train Accuracy: 0.938\n",
      "Validation Accuracy: 0.82\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 122\n",
      "Train Accuracy: 0.961\n",
      "Validation Accuracy: 0.847\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 123\n",
      "Train Accuracy: 0.959\n",
      "Validation Accuracy: 0.841\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 124\n",
      "Train Accuracy: 0.971\n",
      "Validation Accuracy: 0.884\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 125\n",
      "Train Accuracy: 0.965\n",
      "Validation Accuracy: 0.889\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 126\n",
      "Train Accuracy: 0.95\n",
      "Validation Accuracy: 0.878\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 127\n",
      "Train Accuracy: 0.965\n",
      "Validation Accuracy: 0.868\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 128\n",
      "Train Accuracy: 0.963\n",
      "Validation Accuracy: 0.852\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 129\n",
      "Train Accuracy: 0.965\n",
      "Validation Accuracy: 0.873\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 130\n",
      "Train Accuracy: 0.961\n",
      "Validation Accuracy: 0.857\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 131\n",
      "Train Accuracy: 0.95\n",
      "Validation Accuracy: 0.847\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 132\n",
      "Train Accuracy: 0.938\n",
      "Validation Accuracy: 0.81\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 133\n",
      "Train Accuracy: 0.951\n",
      "Validation Accuracy: 0.841\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 134\n",
      "Train Accuracy: 0.889\n",
      "Validation Accuracy: 0.762\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 135\n",
      "Train Accuracy: 0.943\n",
      "Validation Accuracy: 0.841\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 136\n",
      "Train Accuracy: 0.953\n",
      "Validation Accuracy: 0.815\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 137\n",
      "Train Accuracy: 0.975\n",
      "Validation Accuracy: 0.852\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 138\n",
      "Train Accuracy: 0.975\n",
      "Validation Accuracy: 0.873\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 139\n",
      "Train Accuracy: 0.973\n",
      "Validation Accuracy: 0.841\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 140\n",
      "Train Accuracy: 0.976\n",
      "Validation Accuracy: 0.852\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 141\n",
      "Train Accuracy: 0.966\n",
      "Validation Accuracy: 0.862\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 142\n",
      "Train Accuracy: 0.971\n",
      "Validation Accuracy: 0.878\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 143\n",
      "Train Accuracy: 0.975\n",
      "Validation Accuracy: 0.868\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 144\n",
      "Train Accuracy: 0.964\n",
      "Validation Accuracy: 0.868\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 145\n",
      "Train Accuracy: 0.94\n",
      "Validation Accuracy: 0.862\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 146\n",
      "Train Accuracy: 0.94\n",
      "Validation Accuracy: 0.82\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 147\n",
      "Train Accuracy: 0.948\n",
      "Validation Accuracy: 0.852\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 148\n",
      "Train Accuracy: 0.945\n",
      "Validation Accuracy: 0.82\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 149\n",
      "Train Accuracy: 0.961\n",
      "Validation Accuracy: 0.804\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 150\n",
      "Train Accuracy: 0.96\n",
      "Validation Accuracy: 0.831\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 151\n",
      "Train Accuracy: 0.949\n",
      "Validation Accuracy: 0.841\n",
      "-----------------------\n",
      "-----------------------\n",
      "Epoch 152\n",
      "Train Accuracy: 0.961\n",
      "Validation Accuracy: 0.868\n",
      "-----------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-697-120e709a12a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                       \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                       trainP[s:e])\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mtotal_cost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for t in range(args[\"nepoch\"]):\n",
    "    np.random.shuffle(batches)\n",
    "    for i in range(args[\"inner_nepoch\"]):\n",
    "        np.random.shuffle(pre_batches)\n",
    "        pre_total_cost = 0.0\n",
    "        for s, e in pre_batches:\n",
    "            pretrain_loss = model.batch_pretrain(\n",
    "                Triples[s:e], trainQ[0:args[\"batch_size\"]],\n",
    "                trainA[0:args[\"batch_size\"]],\n",
    "                np.argmax(trainA[0:args[\"batch_size\"]],\n",
    "                          axis=1), trainP[0:args[\"batch_size\"]])\n",
    "            optimizer.zero_grad()\n",
    "            pretrain_loss.backward()\n",
    "            optimizer.step()\n",
    "    total_cost = 0.0\n",
    "    \n",
    "    for s, e in batches:\n",
    "        total_cost = model(Triples[s:e], trainQ[s:e], trainA[s:e],\n",
    "                                      np.argmax(trainA[s:e], axis=1),\n",
    "                                      trainP[s:e])\n",
    "        optimizer.zero_grad()\n",
    "        total_cost.backward()\n",
    "        optimizer.step()\n",
    "    if t % 1 == 0:\n",
    "        \n",
    "        train_preds = model.predict(Triples,trainQ,trainP)\n",
    "        train_acc = MultiAcc(trainP,train_preds, model._path_size)\n",
    "        train_true_acc = InSet(trainP,trainS,train_preds)\n",
    "\n",
    "        val_preds = model.predict(Triples,validQ, validP)\n",
    "        val_acc = MultiAcc(validP,val_preds,model._path_size)\n",
    "        val_true_acc = InSet(validP,validS,val_preds)\n",
    "\n",
    "\n",
    "        print('-----------------------')\n",
    "        print('Epoch', t)\n",
    "        print('Train Accuracy:', train_true_acc)\n",
    "        print('Validation Accuracy:', val_true_acc)               \n",
    "        print('-----------------------')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bit2f7b29e352034ae798b05d7e5703bc90"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
